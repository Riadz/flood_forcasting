{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utils import toTorchTensers, NormalizeData\n",
    "from Models import ForcastModelMulti\n",
    "\n",
    "base_url = r'.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "DATA = np.genfromtxt(r'./data/dermatology.data', delimiter=',')\n",
    "np.random.seed(5)\n",
    "np.random.shuffle(DATA)\n",
    "split_point = math.floor(len(DATA) * 0.75)\n",
    "\n",
    "train_x, train_y = DATA[:split_point, :-1], DATA[:split_point, -1]\n",
    "test_x, test_y = DATA[split_point:, :-1], DATA[split_point:, -1]\n",
    "\n",
    "[train_x, train_y, test_x, test_y] = toTorchTensers(\n",
    "  train_x, train_y, test_x, test_y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚙ training ...\n",
      "epoche: 0, loss: 0.11923551, execution time: 0.2s\n",
      "epoche: 1, loss: 0.08466261, execution time: 0.2s\n",
      "epoche: 2, loss: 0.02256653, execution time: 0.2s\n",
      "epoche: 3, loss: 0.00272097, execution time: 0.2s\n",
      "epoche: 4, loss: 0.00925115, execution time: 0.2s\n",
      "epoche: 5, loss: 0.00602257, execution time: 0.2s\n",
      "epoche: 6, loss: 0.01057364, execution time: 0.2s\n",
      "epoche: 7, loss: 0.04807617, execution time: 0.2s\n",
      "epoche: 8, loss: 0.00019153, execution time: 0.2s\n",
      "epoche: 9, loss: 0.08054438, execution time: 0.2s\n",
      "epoche: 10, loss: 0.04878192, execution time: 0.2s\n",
      "epoche: 11, loss: 0.00194950, execution time: 0.2s\n",
      "epoche: 12, loss: 0.11392984, execution time: 0.2s\n",
      "epoche: 13, loss: 0.00000000, execution time: 0.2s\n",
      "epoche: 14, loss: 0.00000002, execution time: 0.2s\n",
      "epoche: 15, loss: 0.10260058, execution time: 0.2s\n",
      "epoche: 16, loss: 0.00000346, execution time: 0.2s\n",
      "epoche: 17, loss: 0.23318546, execution time: 0.2s\n",
      "epoche: 18, loss: 0.00001125, execution time: 0.2s\n",
      "epoche: 19, loss: 0.00000002, execution time: 0.2s\n",
      "epoche: 20, loss: 0.00192463, execution time: 0.2s\n",
      "epoche: 21, loss: 0.00015929, execution time: 0.2s\n",
      "epoche: 22, loss: 0.09390473, execution time: 0.2s\n",
      "epoche: 23, loss: 0.03831173, execution time: 0.2s\n",
      "epoche: 24, loss: 0.30632320, execution time: 0.2s\n",
      "epoche: 25, loss: 0.00075833, execution time: 0.3s\n",
      "epoche: 26, loss: 0.00550032, execution time: 0.2s\n",
      "epoche: 27, loss: 0.13589717, execution time: 0.2s\n",
      "epoche: 28, loss: 0.21293223, execution time: 0.2s\n",
      "epoche: 29, loss: 0.05198335, execution time: 0.2s\n",
      "epoche: 30, loss: 0.00115417, execution time: 0.2s\n",
      "epoche: 31, loss: 0.04557082, execution time: 0.2s\n",
      "epoche: 32, loss: 0.00060356, execution time: 0.2s\n",
      "epoche: 33, loss: 0.03701227, execution time: 0.2s\n",
      "epoche: 34, loss: 0.00000000, execution time: 0.2s\n",
      "epoche: 35, loss: 0.07824364, execution time: 0.2s\n",
      "epoche: 36, loss: 0.00000000, execution time: 0.2s\n",
      "epoche: 37, loss: 0.00020916, execution time: 0.2s\n",
      "epoche: 38, loss: 0.05326171, execution time: 0.2s\n",
      "epoche: 39, loss: 0.24524598, execution time: 0.2s\n",
      "epoche: 40, loss: 0.00036943, execution time: 0.2s\n",
      "epoche: 41, loss: 0.01341403, execution time: 0.2s\n",
      "epoche: 42, loss: 0.00000000, execution time: 0.2s\n",
      "epoche: 43, loss: 0.00217901, execution time: 0.2s\n",
      "epoche: 44, loss: 0.00000000, execution time: 0.2s\n",
      "epoche: 45, loss: 0.00092931, execution time: 0.2s\n",
      "epoche: 46, loss: 0.00080862, execution time: 0.2s\n",
      "epoche: 47, loss: 0.08898067, execution time: 0.2s\n",
      "epoche: 48, loss: 0.00438950, execution time: 0.2s\n",
      "epoche: 49, loss: 0.01469507, execution time: 0.2s\n",
      "epoche: 50, loss: 0.00118795, execution time: 0.2s\n",
      "epoche: 51, loss: 0.16893642, execution time: 0.2s\n",
      "epoche: 52, loss: 0.00000000, execution time: 0.2s\n",
      "epoche: 53, loss: 0.22917335, execution time: 0.2s\n",
      "epoche: 54, loss: 0.33332905, execution time: 0.2s\n",
      "epoche: 55, loss: 0.00000000, execution time: 0.2s\n",
      "epoche: 56, loss: 0.33216926, execution time: 0.2s\n",
      "epoche: 57, loss: 0.21849597, execution time: 0.2s\n",
      "epoche: 58, loss: 0.00145479, execution time: 0.2s\n",
      "epoche: 59, loss: 0.00615991, execution time: 0.2s\n",
      "epoche: 60, loss: 0.00004426, execution time: 0.2s\n",
      "epoche: 61, loss: 0.00070317, execution time: 0.2s\n",
      "epoche: 62, loss: 0.05774084, execution time: 0.2s\n",
      "epoche: 63, loss: 0.00096466, execution time: 0.2s\n",
      "epoche: 64, loss: 0.23289806, execution time: 0.2s\n",
      "epoche: 65, loss: 0.18580429, execution time: 0.2s\n",
      "epoche: 66, loss: 0.05600486, execution time: 0.2s\n",
      "epoche: 67, loss: 0.28209725, execution time: 0.2s\n",
      "epoche: 68, loss: 0.02028142, execution time: 0.2s\n",
      "epoche: 69, loss: 0.01038923, execution time: 0.2s\n",
      "epoche: 70, loss: 0.00626918, execution time: 0.2s\n",
      "epoche: 71, loss: 0.00241778, execution time: 0.2s\n",
      "epoche: 72, loss: 0.05483495, execution time: 0.2s\n",
      "epoche: 73, loss: 0.33332989, execution time: 0.2s\n",
      "epoche: 74, loss: 0.00001494, execution time: 0.2s\n",
      "epoche: 75, loss: 0.07340884, execution time: 0.2s\n",
      "epoche: 76, loss: 0.02866026, execution time: 0.2s\n",
      "epoche: 77, loss: 0.00004431, execution time: 0.2s\n",
      "epoche: 78, loss: 0.00011524, execution time: 0.2s\n",
      "epoche: 79, loss: 0.00203867, execution time: 0.2s\n",
      "epoche: 80, loss: 0.31249103, execution time: 0.2s\n",
      "epoche: 81, loss: 0.13590071, execution time: 0.2s\n",
      "epoche: 82, loss: 0.03025185, execution time: 0.2s\n",
      "epoche: 83, loss: 0.00021905, execution time: 0.2s\n",
      "epoche: 84, loss: 0.00000720, execution time: 0.2s\n",
      "epoche: 85, loss: 0.00000000, execution time: 0.2s\n",
      "epoche: 86, loss: 0.30570075, execution time: 0.2s\n",
      "epoche: 87, loss: 0.33325782, execution time: 0.2s\n",
      "epoche: 88, loss: 0.25756425, execution time: 0.2s\n",
      "epoche: 89, loss: 0.00013593, execution time: 0.2s\n",
      "epoche: 90, loss: 0.18982680, execution time: 0.2s\n",
      "epoche: 91, loss: 0.33333334, execution time: 0.2s\n",
      "epoche: 92, loss: 0.00003163, execution time: 0.2s\n",
      "epoche: 93, loss: 0.11073145, execution time: 0.2s\n",
      "epoche: 94, loss: 0.00013067, execution time: 0.2s\n",
      "epoche: 95, loss: 0.00000211, execution time: 0.2s\n",
      "epoche: 96, loss: 0.00001995, execution time: 0.2s\n",
      "epoche: 97, loss: 0.00239974, execution time: 0.2s\n",
      "epoche: 98, loss: 0.00276398, execution time: 0.2s\n",
      "epoche: 99, loss: 0.00050601, execution time: 0.2s\n",
      "✅ training ended ,final loss: 0.00050601, time: 18.2s\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "model = ForcastModelMulti(input=34, output=int(max(DATA[:, -1])))\n",
    "model.fit(train_x, train_y, epoches=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.0004, acc: 0.9326\n",
      "loss: 0.0000, acc: 0.9222\n"
     ]
    }
   ],
   "source": [
    "# testing\n",
    "model.test(train_x, train_y)\n",
    "model.test(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.0000, acc: 0.9556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\container.py:141: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    }
   ],
   "source": [
    "DATA = np.genfromtxt(r'./data/dermatology.data', delimiter=',')\n",
    "np.random.seed(5)\n",
    "np.random.shuffle(DATA)\n",
    "split_point = math.floor(len(DATA) * 0.75)\n",
    "\n",
    "train_x, train_y = DATA[:split_point, :-1], DATA[:split_point, -1]\n",
    "test_x, test_y = DATA[split_point:, :-1], DATA[split_point:, -1]\n",
    "\n",
    "[train_x, train_y, test_x, test_y] = toTorchTensers(\n",
    "  train_x, train_y, test_x, test_y\n",
    ")\n",
    "\n",
    "# model\n",
    "loaded_model = ForcastModelMulti(input=34, output=6)\n",
    "loaded_model.load_state_dict(\n",
    "    torch.load(f'{base_url}/models/forcast_model_20-04_12-02-58.pt')\n",
    ")\n",
    "loaded_model.eval()\n",
    "\n",
    "loaded_model.test(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ model saved as \"forcast_model_20-04_12-04-18.pt\"\n"
     ]
    }
   ],
   "source": [
    "# model.save()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "72c063d6035d88959ce5488d2496817d169a349dc57db45346e17e4ac662e96d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
