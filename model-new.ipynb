{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utils import toTorchTensers, NormalizeData\n",
    "from Models import ForcastModelMulti\n",
    "\n",
    "base_url = r'.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138 341 347 91\n",
      "torch.Size([664, 12]) torch.Size([664])\n"
     ]
    }
   ],
   "source": [
    "# data\n",
    "DATA = np.genfromtxt(r'./data/clustered_egypt.csv', delimiter=',')\n",
    "print(\n",
    "    (DATA == 1).sum(),\n",
    "    (DATA == 2).sum(),\n",
    "    (DATA == 3).sum(),\n",
    "    (DATA == 4).sum(),\n",
    ")\n",
    "np.random.seed(5)\n",
    "np.random.shuffle(DATA)\n",
    "split_point = math.floor(len(DATA) * 0.75)\n",
    "\n",
    "train_x, train_y = DATA[:split_point, 1:], DATA[:split_point, 0]\n",
    "test_x, test_y = DATA[split_point:, 1:], DATA[split_point:, 0]\n",
    "\n",
    "[train_x, train_y, test_x, test_y] = toTorchTensers(\n",
    "  train_x, train_y, test_x, test_y\n",
    ")\n",
    "\n",
    "print(train_x.shape, train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚙ training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Riad\\Desktop\\MASTER 2\\PROJET_CODE\\venv\\lib\\site-packages\\torch\\nn\\modules\\container.py:141: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoche: 0, loss: 0.157460376620, execution time: 1.1s\n",
      "epoche: 1, loss: 0.015129139647, execution time: 1.0s\n",
      "epoche: 2, loss: 0.002154101850, execution time: 1.0s\n",
      "epoche: 3, loss: 0.000776747067, execution time: 1.0s\n",
      "epoche: 4, loss: 0.000467372331, execution time: 1.1s\n",
      "epoche: 5, loss: 0.000338245532, execution time: 1.0s\n",
      "epoche: 6, loss: 0.000231982413, execution time: 1.0s\n",
      "epoche: 7, loss: 0.000099531935, execution time: 1.0s\n",
      "epoche: 8, loss: 0.000247167074, execution time: 1.0s\n",
      "epoche: 9, loss: 0.000064780776, execution time: 1.0s\n",
      "epoche: 10, loss: 0.000111817542, execution time: 1.1s\n",
      "epoche: 11, loss: 0.000022105856, execution time: 1.1s\n",
      "epoche: 12, loss: 0.000111385452, execution time: 1.1s\n",
      "epoche: 13, loss: 0.000465295278, execution time: 1.0s\n",
      "epoche: 14, loss: 0.001080431743, execution time: 1.1s\n",
      "epoche: 15, loss: 0.000218417408, execution time: 1.0s\n",
      "epoche: 16, loss: 0.001328821061, execution time: 1.0s\n",
      "epoche: 17, loss: 0.001523721032, execution time: 1.0s\n",
      "epoche: 18, loss: 0.000523947179, execution time: 1.0s\n",
      "epoche: 19, loss: 0.000071528673, execution time: 1.1s\n",
      "epoche: 20, loss: 0.000032219166, execution time: 1.1s\n",
      "epoche: 21, loss: 0.000973301765, execution time: 1.1s\n",
      "epoche: 22, loss: 0.000156636816, execution time: 1.0s\n",
      "epoche: 23, loss: 0.000184615958, execution time: 1.0s\n",
      "epoche: 24, loss: 0.000156675291, execution time: 1.1s\n",
      "epoche: 25, loss: 0.000170639891, execution time: 1.0s\n",
      "epoche: 26, loss: 0.000142247256, execution time: 1.0s\n",
      "epoche: 27, loss: 0.000136859511, execution time: 1.0s\n",
      "epoche: 28, loss: 0.000383277074, execution time: 1.0s\n",
      "epoche: 29, loss: 0.000027700915, execution time: 1.0s\n",
      "epoche: 30, loss: 0.000042322019, execution time: 1.0s\n",
      "epoche: 31, loss: 0.000053378582, execution time: 1.0s\n",
      "epoche: 32, loss: 0.000110624591, execution time: 1.0s\n",
      "epoche: 33, loss: 0.000474132074, execution time: 1.0s\n",
      "epoche: 34, loss: 0.000164090947, execution time: 1.0s\n",
      "epoche: 35, loss: 0.000159598014, execution time: 1.0s\n",
      "epoche: 36, loss: 0.000109213390, execution time: 1.0s\n",
      "epoche: 37, loss: 0.000048027476, execution time: 1.0s\n",
      "epoche: 38, loss: 0.000007043813, execution time: 1.0s\n",
      "epoche: 39, loss: 0.000340857165, execution time: 1.0s\n",
      "epoche: 40, loss: 0.000166556623, execution time: 1.0s\n",
      "epoche: 41, loss: 0.000056336976, execution time: 1.0s\n",
      "epoche: 42, loss: 0.000266847288, execution time: 1.0s\n",
      "epoche: 43, loss: 0.000017141689, execution time: 1.0s\n",
      "epoche: 44, loss: 0.000009714153, execution time: 1.0s\n",
      "epoche: 45, loss: 0.000023620385, execution time: 1.1s\n",
      "epoche: 46, loss: 0.000176981237, execution time: 1.0s\n",
      "epoche: 47, loss: 0.000179703318, execution time: 1.1s\n",
      "epoche: 48, loss: 0.000023820030, execution time: 1.0s\n",
      "epoche: 49, loss: 0.000001154550, execution time: 1.0s\n",
      "epoche: 50, loss: 0.000074853044, execution time: 1.0s\n",
      "epoche: 51, loss: 0.000000167800, execution time: 1.0s\n",
      "epoche: 52, loss: 0.000012701841, execution time: 1.0s\n",
      "epoche: 53, loss: 0.000069974791, execution time: 1.0s\n",
      "epoche: 54, loss: 0.000018195895, execution time: 1.0s\n",
      "epoche: 55, loss: 0.000005526008, execution time: 1.0s\n",
      "epoche: 56, loss: 0.001303758007, execution time: 1.0s\n",
      "epoche: 57, loss: 0.000103597762, execution time: 1.0s\n",
      "epoche: 58, loss: 0.000007726659, execution time: 1.0s\n",
      "epoche: 59, loss: 0.000000164197, execution time: 1.0s\n",
      "epoche: 60, loss: 0.000057804056, execution time: 1.0s\n",
      "epoche: 61, loss: 0.000000197457, execution time: 1.0s\n",
      "epoche: 62, loss: 0.000000743240, execution time: 1.0s\n",
      "epoche: 63, loss: 0.000003946742, execution time: 1.0s\n",
      "epoche: 64, loss: 0.000043002590, execution time: 1.0s\n",
      "epoche: 65, loss: 0.000091071837, execution time: 1.0s\n",
      "epoche: 66, loss: 0.000017399238, execution time: 1.0s\n",
      "epoche: 67, loss: 0.000082505554, execution time: 1.0s\n",
      "epoche: 68, loss: 0.000006326484, execution time: 1.0s\n",
      "epoche: 69, loss: 0.000026775888, execution time: 1.0s\n",
      "epoche: 70, loss: 0.000000047197, execution time: 1.0s\n",
      "epoche: 71, loss: 0.000000020535, execution time: 1.0s\n",
      "epoche: 72, loss: 0.000000020507, execution time: 1.0s\n",
      "epoche: 73, loss: 0.000001328846, execution time: 1.0s\n",
      "epoche: 74, loss: 0.000058498608, execution time: 1.0s\n",
      "epoche: 75, loss: 0.000014683040, execution time: 1.0s\n",
      "epoche: 76, loss: 0.000005365239, execution time: 1.0s\n",
      "epoche: 77, loss: 0.000000030494, execution time: 1.0s\n",
      "epoche: 78, loss: 0.000485582685, execution time: 1.0s\n",
      "epoche: 79, loss: 0.000001107955, execution time: 1.0s\n",
      "epoche: 80, loss: 0.000000047515, execution time: 1.0s\n",
      "epoche: 81, loss: 0.000007587301, execution time: 1.0s\n",
      "epoche: 82, loss: 0.000076517383, execution time: 1.1s\n",
      "epoche: 83, loss: 0.000000001658, execution time: 1.1s\n",
      "epoche: 84, loss: 0.000000223168, execution time: 1.1s\n",
      "epoche: 85, loss: 0.000002080204, execution time: 1.0s\n",
      "epoche: 86, loss: 0.000042542979, execution time: 1.0s\n",
      "epoche: 87, loss: 0.000011119229, execution time: 1.1s\n",
      "epoche: 88, loss: 0.000000000000, execution time: 1.1s\n",
      "epoche: 89, loss: 0.000000000217, execution time: 1.0s\n",
      "epoche: 90, loss: 0.000000282554, execution time: 1.0s\n",
      "epoche: 91, loss: 0.000000631733, execution time: 1.0s\n",
      "epoche: 92, loss: 0.000000059631, execution time: 1.0s\n",
      "epoche: 93, loss: 0.000000001002, execution time: 1.0s\n",
      "epoche: 94, loss: 0.000000024841, execution time: 1.1s\n",
      "epoche: 95, loss: 0.000198094931, execution time: 1.0s\n",
      "epoche: 96, loss: 0.000000003924, execution time: 1.1s\n",
      "epoche: 97, loss: 0.000000007874, execution time: 1.1s\n",
      "epoche: 98, loss: 0.000000136875, execution time: 1.1s\n",
      "epoche: 99, loss: 0.000000000803, execution time: 1.1s\n",
      "✅ training ended ,final loss: 0.000000000803, time: 104.2s\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "model = ForcastModelMulti(input=12, output=int(max(DATA[:, 0])))\n",
    "model.fit(train_x, train_y, epoches=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.4528, acc: 0.8964\n",
      "loss: 0.0000, acc: 0.9247\n"
     ]
    }
   ],
   "source": [
    "# testing\n",
    "model.test(test_x, test_y)\n",
    "model.test(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "72c063d6035d88959ce5488d2496817d169a349dc57db45346e17e4ac662e96d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
