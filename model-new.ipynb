{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utils import toTorchTensers, NormalizeData\n",
    "from Models import ForcastModelMulti\n",
    "\n",
    "base_url = r'.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426 434 393 434\n",
      "torch.Size([1256, 12]) torch.Size([1256])\n"
     ]
    }
   ],
   "source": [
    "# data\n",
    "DATA = np.genfromtxt(r'./data/clustered_vietnam.csv', delimiter=',')\n",
    "print(\n",
    "    (DATA == 1).sum(),\n",
    "    (DATA == 2).sum(),\n",
    "    (DATA == 3).sum(),\n",
    "    (DATA == 4).sum(),\n",
    ")\n",
    "np.random.seed(5)\n",
    "np.random.shuffle(DATA)\n",
    "split_point = math.floor(len(DATA) * 0.75)\n",
    "\n",
    "train_x, train_y = DATA[:split_point, 1:], DATA[:split_point, 0]\n",
    "test_x, test_y = DATA[split_point:, 1:], DATA[split_point:, 0]\n",
    "\n",
    "[train_x, train_y, test_x, test_y] = toTorchTensers(\n",
    "  train_x, train_y, test_x, test_y\n",
    ")\n",
    "\n",
    "print(train_x.shape, train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚙ training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Riad\\Desktop\\MASTER 2\\PROJET_CODE\\venv\\lib\\site-packages\\torch\\nn\\modules\\container.py:141: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoche: 0, loss: 0.003098446410, execution time: 2.0s\n",
      "epoche: 1, loss: 0.002218023874, execution time: 2.0s\n",
      "epoche: 2, loss: 0.002267148346, execution time: 2.0s\n",
      "epoche: 3, loss: 0.002811716869, execution time: 2.0s\n",
      "epoche: 4, loss: 0.003414874664, execution time: 2.0s\n",
      "epoche: 5, loss: 0.002318799961, execution time: 2.3s\n",
      "epoche: 6, loss: 0.003472023876, execution time: 2.0s\n",
      "epoche: 7, loss: 0.000395340583, execution time: 2.0s\n",
      "epoche: 8, loss: 0.000235553234, execution time: 1.9s\n",
      "epoche: 9, loss: 0.001231980976, execution time: 1.9s\n",
      "epoche: 10, loss: 0.001195568824, execution time: 1.9s\n",
      "epoche: 11, loss: 0.000957697630, execution time: 1.9s\n",
      "epoche: 12, loss: 0.000170187777, execution time: 1.9s\n",
      "epoche: 13, loss: 0.001303175930, execution time: 1.9s\n",
      "epoche: 14, loss: 0.000799252768, execution time: 1.9s\n",
      "epoche: 15, loss: 0.000855374266, execution time: 1.9s\n",
      "epoche: 16, loss: 0.001912433887, execution time: 1.9s\n",
      "epoche: 17, loss: 0.000671166694, execution time: 1.9s\n",
      "epoche: 18, loss: 0.001103360439, execution time: 1.9s\n",
      "epoche: 19, loss: 0.000370694906, execution time: 1.9s\n",
      "epoche: 20, loss: 0.000557279738, execution time: 1.8s\n",
      "epoche: 21, loss: 0.000910484698, execution time: 2.2s\n",
      "epoche: 22, loss: 0.000238565277, execution time: 2.0s\n",
      "epoche: 23, loss: 0.000700999517, execution time: 2.4s\n",
      "epoche: 24, loss: 0.000656974968, execution time: 2.1s\n",
      "epoche: 25, loss: 0.000253541017, execution time: 2.0s\n",
      "epoche: 26, loss: 0.000160906347, execution time: 2.0s\n",
      "epoche: 27, loss: 0.000097602424, execution time: 1.9s\n",
      "epoche: 28, loss: 0.000383551931, execution time: 1.8s\n",
      "epoche: 29, loss: 0.000178915245, execution time: 1.9s\n",
      "epoche: 30, loss: 0.000238081630, execution time: 1.9s\n",
      "epoche: 31, loss: 0.000362329884, execution time: 2.0s\n",
      "epoche: 32, loss: 0.000779797672, execution time: 1.9s\n",
      "epoche: 33, loss: 0.000212234329, execution time: 1.9s\n",
      "epoche: 34, loss: 0.000380154088, execution time: 1.8s\n",
      "epoche: 35, loss: 0.000206353143, execution time: 1.9s\n",
      "epoche: 36, loss: 0.000192838488, execution time: 1.9s\n",
      "epoche: 37, loss: 0.000459067582, execution time: 2.2s\n",
      "epoche: 38, loss: 0.000244990719, execution time: 2.1s\n",
      "epoche: 39, loss: 0.000123778984, execution time: 2.3s\n",
      "epoche: 40, loss: 0.000049502200, execution time: 2.2s\n",
      "epoche: 41, loss: 0.000771847088, execution time: 2.1s\n",
      "epoche: 42, loss: 0.000303951267, execution time: 2.0s\n",
      "epoche: 43, loss: 0.000266804709, execution time: 2.1s\n",
      "epoche: 44, loss: 0.000324478548, execution time: 2.0s\n",
      "epoche: 45, loss: 0.000139396492, execution time: 2.1s\n",
      "epoche: 46, loss: 0.000095963660, execution time: 2.4s\n",
      "epoche: 47, loss: 0.000068725174, execution time: 3.0s\n",
      "epoche: 48, loss: 0.000177619178, execution time: 2.1s\n",
      "epoche: 49, loss: 0.000323758781, execution time: 3.1s\n",
      "epoche: 50, loss: 0.000143809943, execution time: 2.3s\n",
      "epoche: 51, loss: 0.000411507819, execution time: 2.1s\n",
      "epoche: 52, loss: 0.000171654960, execution time: 2.5s\n",
      "epoche: 53, loss: 0.000205610442, execution time: 2.1s\n",
      "epoche: 54, loss: 0.000204532349, execution time: 2.2s\n",
      "epoche: 55, loss: 0.000213291496, execution time: 2.2s\n",
      "epoche: 56, loss: 0.000295092672, execution time: 2.3s\n",
      "epoche: 57, loss: 0.000275866070, execution time: 2.3s\n",
      "epoche: 58, loss: 0.000243712013, execution time: 2.4s\n",
      "epoche: 59, loss: 0.000059718121, execution time: 2.3s\n",
      "epoche: 60, loss: 0.000095824274, execution time: 3.5s\n",
      "epoche: 61, loss: 0.000184534496, execution time: 2.1s\n",
      "epoche: 62, loss: 0.000313406345, execution time: 1.9s\n",
      "epoche: 63, loss: 0.000189499493, execution time: 1.9s\n",
      "epoche: 64, loss: 0.000207435951, execution time: 1.9s\n",
      "epoche: 65, loss: 0.001108124154, execution time: 2.2s\n",
      "epoche: 66, loss: 0.000034039978, execution time: 2.1s\n",
      "epoche: 67, loss: 0.000162234574, execution time: 2.1s\n",
      "epoche: 68, loss: 0.000419566757, execution time: 2.0s\n",
      "epoche: 69, loss: 0.000400689431, execution time: 2.0s\n",
      "epoche: 70, loss: 0.000238276829, execution time: 2.1s\n",
      "epoche: 71, loss: 0.000127638836, execution time: 2.4s\n",
      "epoche: 72, loss: 0.000290353259, execution time: 2.2s\n",
      "epoche: 73, loss: 0.000250533165, execution time: 2.3s\n",
      "epoche: 74, loss: 0.000044502121, execution time: 2.4s\n",
      "epoche: 75, loss: 0.000660226389, execution time: 2.4s\n",
      "epoche: 76, loss: 0.000053604635, execution time: 2.5s\n",
      "epoche: 77, loss: 0.000238684763, execution time: 2.3s\n",
      "epoche: 78, loss: 0.001599250245, execution time: 2.5s\n",
      "epoche: 79, loss: 0.000628206762, execution time: 2.3s\n",
      "epoche: 80, loss: 0.000835831393, execution time: 2.3s\n",
      "epoche: 81, loss: 0.000057290606, execution time: 2.2s\n",
      "epoche: 82, loss: 0.000476732966, execution time: 2.3s\n",
      "epoche: 83, loss: 0.000167187391, execution time: 2.0s\n",
      "epoche: 84, loss: 0.000282553257, execution time: 2.0s\n",
      "epoche: 85, loss: 0.000501162955, execution time: 2.3s\n",
      "epoche: 86, loss: 0.000042891512, execution time: 2.4s\n",
      "epoche: 87, loss: 0.000355252036, execution time: 2.1s\n",
      "epoche: 88, loss: 0.000103528677, execution time: 2.3s\n",
      "epoche: 89, loss: 0.000069827031, execution time: 2.1s\n",
      "epoche: 90, loss: 0.000134598085, execution time: 2.1s\n",
      "epoche: 91, loss: 0.000599483028, execution time: 2.1s\n",
      "epoche: 92, loss: 0.000206552169, execution time: 2.2s\n",
      "epoche: 93, loss: 0.000064614913, execution time: 2.3s\n",
      "epoche: 94, loss: 0.000156053778, execution time: 2.4s\n",
      "epoche: 95, loss: 0.000133138587, execution time: 2.4s\n",
      "epoche: 96, loss: 0.000203813252, execution time: 2.2s\n",
      "epoche: 97, loss: 0.000147689701, execution time: 2.2s\n",
      "epoche: 98, loss: 0.000131472596, execution time: 2.4s\n",
      "epoche: 99, loss: 0.000031739590, execution time: 2.1s\n",
      "✅ training ended ,final loss: 0.000031739590, time: 214.0s\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "model = ForcastModelMulti(input=12, output=int(max(DATA[:, 0])))\n",
    "model.fit(train_x, train_y, epoches=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.0000, acc: 0.9618\n",
      "loss: 0.0000, acc: 0.9777\n"
     ]
    }
   ],
   "source": [
    "# testing\n",
    "model.test(test_x, test_y)\n",
    "model.test(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ model saved as \"forcast_model_29-04_17-34-02.pt\"\n"
     ]
    }
   ],
   "source": [
    "model.save()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "72c063d6035d88959ce5488d2496817d169a349dc57db45346e17e4ac662e96d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
