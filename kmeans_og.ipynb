{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "from kmeans_pytorch import kmeans\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import toTorchTensers, NormalizeData\n",
    "\n",
    "base_url = r'.'\n",
    "\n",
    "data_url = r'./data/Data.xlsx'\n",
    "data_egypt = pd.read_excel(data_url, sheet_name='Egypt')\n",
    "data_vietnam = pd.read_excel(data_url, sheet_name='Vietnam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([827, 12])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data\n",
    "DATA = data_vietnam\n",
    "DATA = NormalizeData(DATA)\n",
    "DATA = DATA[DATA['Flood'] == 1]\n",
    "DATA = DATA.to_numpy()\n",
    "\n",
    "[X] = toTorchTensers(DATA[:, 1:])\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running k-means on cpu..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[running kmeans]: 7it [00:00, 437.81it/s, center_shift=0.000086, iteration=7, tol=0.000100]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 1 0 0 1 0 0 1 0 1 0 0 0 0 0 1 0 1 1 1 1 0 0 0 1 1 1 0 0 1 1 1 0 1\n",
      " 1 1 0 1 1 1 0 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1\n",
      " 0 0 1 0 0 1 1 0 1 0 1 0 1 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 1 0\n",
      " 1 0 0 0 1 0 1 0 1 1 1 1 0 0 1 0 0 0 0 0 1 1 0 0 0 1 1 1 0 0 1 1 1 1 0 1 1\n",
      " 1 1 0 1 1 1 1 1 1 0 0 1 0 0 0 0 1 0 1 0 1 1 0 1 1 1 1 1 0 0 1 1 1 0 1 0 0\n",
      " 0 0 1 1 1 0 0 0 0 0 1 1 0 0 1 0 1 1 0 1 1 0 1 0 1 0 0 1 0 1 1 1 1 1 0 1 1\n",
      " 0 0 0 1 0 1 1 0 0 0 1 0 0 1 0 1 1 0 0 0 1 0 0 1 1 1 0 0 1 0 1 1 1 1 1 1 1\n",
      " 0 0 0 1 0 1 1 1 0 1 1 0 0 0 1 1 1 0 1 0 1 1 1 1 1 0 1 1 1 0 1 1 0 0 0 0 1\n",
      " 0 1 0 0 1 1 0 1 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 1 0 0 0 1 1 1 0 0 0 1 0 1 0\n",
      " 1 1 1 0 0 0 1 1 1 1 0 1 1 0 1 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 0 0 1 1\n",
      " 0 0 1 1 1 1 0 0 1 1 0 0 1 1 1 1 0 1 0 0 1 0 1 0 0 1 1 1 1 0 1 0 0 0 1 0 0\n",
      " 1 1 1 1 1 0 1 0 0 0 0 1 1 0 0 0 0 0 1 1 1 0 1 1 0 0 0 1 0 1 0 1 0 0 1 1 1\n",
      " 1 1 0 0 0 1 0 1 1 0 1 0 0 1 1 0 1 1 0 0 0 0 0 1 1 1 0 0 1 0 0 0 0 0 1 1 0\n",
      " 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 1 1 0 1 1 1 1 0 1 1 1 0 0 1 0 0 0\n",
      " 0 1 1 1 0 0 1 1 1 1 1 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1 1 1 1 0 0 1 1 1 1 1\n",
      " 1 1 1 1 0 0 1 1 1 1 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 0 0 0 1 0 0 0 1 0 0 1\n",
      " 1 0 0 0 1 0 1 0 1 1 0 1 0 1 0 1 0 0 1 1 1 1 0 1 0 0 0 0 1 0 0 1 0 1 0 0 0\n",
      " 0 1 1 1 0 1 0 1 0 1 1 1 1 0 0 1 0 0 1 0 1 0 0 0 1 0 0 1 1 0 1 1 1 0 0 0 0\n",
      " 0 0 0 1 1 0 1 1 1 0 0 1 0 0 0 1 1 0 0 1 0 1 1 0 0 0 1 0 1 0 1 0 0 0 1 0 0\n",
      " 1 0 0 0 1 1 1 0 1 0 1 0 1 0 1 1 0 0 1 1 0 0 0 1 1 0 1 1 1 0 1 1 1 0 1 0 1\n",
      " 0 0 0 1 1 0 1 1 0 1 1 1 1 1 0 1 1 0 1 0 0 0 0 0 1 1 1 1 0 1 1 1 0 1 1 1 1\n",
      " 0 1 0 1 1 1 1 1 1 0 1 0 0 1 0 0 1 0 1 1 1 0 0 1 1 0 0 0 0 0 0 1 0 0 0 1 1\n",
      " 1 1 0 0 1 1 0 1 0 0 1 0 0] 393 434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cluster_x, cluster_centers = kmeans(\n",
    "    X=X, num_clusters=2, distance='cosine'\n",
    ")\n",
    "\n",
    "cluster_x = cluster_x.numpy()\n",
    "# cluster_x +=2\n",
    "print(cluster_x, (cluster_x == 0).sum(), (cluster_x == 1).sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(827, 13) [[0.00000000e+00 3.16380717e-01 7.40053050e-01 ... 1.28289855e-03\n",
      "  2.90096039e-05 6.78796564e-01]\n",
      " [0.00000000e+00 2.91804430e-01 6.14942529e-01 ... 8.40728851e-03\n",
      "  7.45543264e-06 3.99718442e-01]\n",
      " [0.00000000e+00 0.00000000e+00 5.68081344e-01 ... 0.00000000e+00\n",
      "  0.00000000e+00 8.43150880e-01]\n",
      " ...\n",
      " [1.00000000e+00 9.01784037e-01 7.51547303e-01 ... 5.90609355e-03\n",
      "  0.00000000e+00 3.16774254e-01]\n",
      " [0.00000000e+00 3.30716050e-01 7.59062776e-01 ... 2.44927627e-02\n",
      "  5.43066220e-06 2.78822924e-01]\n",
      " [0.00000000e+00 2.90787725e-01 8.39080460e-01 ... 1.79703584e-02\n",
      "  7.96840338e-06 3.23222256e-01]]\n"
     ]
    }
   ],
   "source": [
    "NEW_DATA = np.insert(DATA[:, 1:], -0, cluster_x, axis=1)\n",
    "print(NEW_DATA.shape, NEW_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as ./data/clusters_vien_29-04_17-20-05.csv\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "current_datetime = datetime.now().strftime(\"%d-%m_%H-%M-%S\")\n",
    "path = rf'{base_url}/data/clusters_vien_{current_datetime}.csv'\n",
    "np.savetxt(path, NEW_DATA, delimiter=\",\")\n",
    "\n",
    "print(\"saved as\", path)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "72c063d6035d88959ce5488d2496817d169a349dc57db45346e17e4ac662e96d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
