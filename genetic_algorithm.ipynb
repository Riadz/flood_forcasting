{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from AutoEncoder import AutoEncoder\n",
    "from utils import toTorchTensers, NormalizeData\n",
    "\n",
    "base_url = r'.'\n",
    "\n",
    "data_url = rf'{base_url}/data/Data.xlsx'\n",
    "data_egypt = pd.read_excel(data_url, sheet_name='Egypt')\n",
    "data_vietnam = pd.read_excel(data_url, sheet_name='Vietnam')\n",
    "\n",
    "device = 'cpu'\n",
    "# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device = torch.device(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "DATA = data_egypt\n",
    "DATA = NormalizeData(DATA)\n",
    "DATA = DATA.to_numpy()\n",
    "\n",
    "np.random.seed(1)\n",
    "np.random.shuffle(DATA)\n",
    "split_point = math.floor(len(DATA) * 0.75)\n",
    "\n",
    "train_x, train_y = DATA[:split_point, 1:], DATA[:split_point, 0:1]\n",
    "test_x, test_y = DATA[split_point:, 1:], DATA[split_point:, 0:1]\n",
    "\n",
    "[train_x, train_y, test_x, test_y] = toTorchTensers(\n",
    "    train_x, train_y, test_x, test_y,\n",
    "    device=device\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_min = 3\n",
    "gen_max = 12\n",
    "gen_count = 3\n",
    "\n",
    "population_count = 4\n",
    "generation_count = 100\n",
    "\n",
    "# \n",
    "def generate_individual():\n",
    "  individual = []\n",
    "  for i in range(gen_count):\n",
    "    individual.append(random.randint(gen_min, gen_max))\n",
    "\n",
    "  return individual\n",
    "\n",
    "\n",
    "def generate_population():\n",
    "    population = []\n",
    "    for i in range(population_count):\n",
    "        population.append(generate_individual())\n",
    "\n",
    "    return population\n",
    "\n",
    "\n",
    "def calc_fitnesses(population):\n",
    "  fitnesses = []\n",
    "  for i in range(population_count):\n",
    "    model = AutoEncoder(population[i])\n",
    "    model.fit(train_x, train_x, epoches=1600, batch_size=600, progress=False)\n",
    "    fitnesses.append(model.current_loss)\n",
    "  return fitnesses\n",
    "  \n",
    "\n",
    "def get_best(fitnesses):\n",
    "  return np.argmin(fitnesses)\n",
    "\n",
    "\n",
    "def get_bests(fitnesses, count):\n",
    "    fitnesses = fitnesses[:]\n",
    "    bests = []\n",
    "\n",
    "    for i in range(count):\n",
    "      b = np.argmin(fitnesses)\n",
    "      bests.append(b)\n",
    "\n",
    "      fitnesses.pop(i)\n",
    "    \n",
    "    return bests\n",
    "\n",
    "\n",
    "def breed(p1, p2):\n",
    "    gene1 = random.randint(0, gen_count-1)\n",
    "    gene2 = random.randint(0, gen_count-1)\n",
    "\n",
    "    new = p1[:]\n",
    "\n",
    "    new[gene1] = p2[gene1]\n",
    "    new[gene2] = p2[gene2]\n",
    "\n",
    "    return new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation 1\n",
      "✅ training ended ,final loss: 0.00942987, time: 8.1s\n",
      "✅ training ended ,final loss: 0.01507597, time: 7.5s\n",
      "✅ training ended ,final loss: 0.03940317, time: 8.2s\n",
      "✅ training ended ,final loss: 0.01330483, time: 7.6s\n",
      "Best: 0.00942987110465765\n",
      "generation 2\n",
      "✅ training ended ,final loss: 0.01387687, time: 8.5s\n",
      "✅ training ended ,final loss: 0.01206211, time: 8.2s\n",
      "✅ training ended ,final loss: 0.00824314, time: 8.4s\n",
      "✅ training ended ,final loss: 0.01288559, time: 7.9s\n",
      "Best: 0.00824313797056675\n",
      "generation 3\n",
      "✅ training ended ,final loss: 0.00607302, time: 7.9s\n",
      "✅ training ended ,final loss: 0.03965230, time: 7.8s\n",
      "✅ training ended ,final loss: 0.01401429, time: 8.0s\n",
      "✅ training ended ,final loss: 0.01794920, time: 8.0s\n",
      "Best: 0.00607302226126194\n",
      "generation 4\n",
      "✅ training ended ,final loss: 0.01175040, time: 8.2s\n",
      "✅ training ended ,final loss: 0.01070335, time: 7.7s\n",
      "✅ training ended ,final loss: 0.00809591, time: 7.9s\n",
      "✅ training ended ,final loss: 0.01282744, time: 7.8s\n",
      "Best: 0.008095911704003811\n",
      "generation 5\n",
      "✅ training ended ,final loss: 0.02248298, time: 8.3s\n",
      "✅ training ended ,final loss: 0.01387777, time: 7.6s\n",
      "✅ training ended ,final loss: 0.01271876, time: 7.6s\n",
      "✅ training ended ,final loss: 0.02235269, time: 8.2s\n",
      "Best: 0.012718763202428818\n",
      "generation 6\n",
      "✅ training ended ,final loss: 0.02541343, time: 7.7s\n",
      "✅ training ended ,final loss: 0.03941225, time: 8.1s\n",
      "✅ training ended ,final loss: 0.01251480, time: 7.4s\n",
      "✅ training ended ,final loss: 0.01189547, time: 7.8s\n",
      "Best: 0.011895467527210712\n",
      "generation 7\n",
      "✅ training ended ,final loss: 0.01740398, time: 7.6s\n",
      "✅ training ended ,final loss: 0.01007033, time: 7.5s\n",
      "✅ training ended ,final loss: 0.01565137, time: 7.7s\n",
      "✅ training ended ,final loss: 0.01587637, time: 7.9s\n",
      "Best: 0.01007032673805952\n",
      "generation 8\n",
      "✅ training ended ,final loss: 0.01337853, time: 7.6s\n",
      "✅ training ended ,final loss: 0.01160059, time: 7.6s\n",
      "✅ training ended ,final loss: 0.01057023, time: 7.9s\n",
      "✅ training ended ,final loss: 0.01057307, time: 7.5s\n",
      "Best: 0.010570227168500423\n",
      "generation 9\n",
      "✅ training ended ,final loss: 0.02463046, time: 7.8s\n",
      "✅ training ended ,final loss: 0.01081617, time: 7.6s\n",
      "✅ training ended ,final loss: 0.01041544, time: 7.9s\n",
      "✅ training ended ,final loss: 0.03940321, time: 8.1s\n",
      "Best: 0.010415442287921906\n",
      "generation 10\n",
      "✅ training ended ,final loss: 0.02654505, time: 7.6s\n",
      "✅ training ended ,final loss: 0.02202497, time: 7.8s\n",
      "✅ training ended ,final loss: 0.01354741, time: 7.7s\n",
      "✅ training ended ,final loss: 0.01267656, time: 7.6s\n",
      "Best: 0.012676562182605267\n",
      "generation 11\n",
      "✅ training ended ,final loss: 0.01485441, time: 7.7s\n",
      "✅ training ended ,final loss: 0.01619992, time: 7.5s\n",
      "✅ training ended ,final loss: 0.02127232, time: 7.9s\n",
      "✅ training ended ,final loss: 0.00877859, time: 7.6s\n",
      "Best: 0.008778589777648449\n",
      "generation 12\n",
      "✅ training ended ,final loss: 0.02497391, time: 8.2s\n",
      "✅ training ended ,final loss: 0.01169931, time: 9.4s\n",
      "✅ training ended ,final loss: 0.01706407, time: 8.8s\n",
      "✅ training ended ,final loss: 0.01470281, time: 9.6s\n",
      "Best: 0.011699306778609753\n",
      "generation 13\n",
      "✅ training ended ,final loss: 0.01694257, time: 8.2s\n",
      "✅ training ended ,final loss: 0.01267300, time: 7.8s\n",
      "✅ training ended ,final loss: 0.01093915, time: 7.7s\n",
      "✅ training ended ,final loss: 0.01535577, time: 8.1s\n",
      "Best: 0.010939146392047405\n",
      "generation 14\n",
      "✅ training ended ,final loss: 0.01045136, time: 8.0s\n",
      "✅ training ended ,final loss: 0.02249311, time: 8.0s\n",
      "✅ training ended ,final loss: 0.01287112, time: 8.8s\n",
      "✅ training ended ,final loss: 0.02119412, time: 8.4s\n",
      "Best: 0.0104513606056571\n",
      "generation 15\n",
      "✅ training ended ,final loss: 0.02654153, time: 7.7s\n",
      "✅ training ended ,final loss: 0.03940341, time: 8.1s\n",
      "✅ training ended ,final loss: 0.01756927, time: 7.6s\n",
      "✅ training ended ,final loss: 0.01051619, time: 7.5s\n",
      "Best: 0.010516189970076084\n",
      "generation 16\n",
      "✅ training ended ,final loss: 0.02115176, time: 7.8s\n",
      "✅ training ended ,final loss: 0.01452375, time: 7.9s\n",
      "✅ training ended ,final loss: 0.01888722, time: 8.1s\n",
      "✅ training ended ,final loss: 0.01391562, time: 7.9s\n",
      "Best: 0.013915624469518661\n",
      "generation 17\n",
      "✅ training ended ,final loss: 0.01955535, time: 8.3s\n",
      "✅ training ended ,final loss: 0.00707821, time: 7.2s\n",
      "✅ training ended ,final loss: 0.01299378, time: 7.5s\n",
      "✅ training ended ,final loss: 0.01099542, time: 7.2s\n",
      "Best: 0.0070782131515443325\n",
      "generation 18\n",
      "✅ training ended ,final loss: 0.03940190, time: 7.8s\n",
      "✅ training ended ,final loss: 0.02377718, time: 7.2s\n",
      "✅ training ended ,final loss: 0.01151751, time: 7.1s\n",
      "✅ training ended ,final loss: 0.03941007, time: 8.1s\n",
      "Best: 0.011517508886754513\n",
      "generation 19\n",
      "✅ training ended ,final loss: 0.01747127, time: 7.1s\n",
      "✅ training ended ,final loss: 0.01293403, time: 7.3s\n",
      "✅ training ended ,final loss: 0.01086621, time: 7.3s\n",
      "✅ training ended ,final loss: 0.02025944, time: 7.4s\n",
      "Best: 0.010866214521229267\n",
      "generation 20\n",
      "✅ training ended ,final loss: 0.01043451, time: 7.7s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Riad\\Desktop\\MASTER 2\\PROJET_CODE\\genetic_algorithm.ipynb Cell 4'\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Riad/Desktop/MASTER%202/PROJET_CODE/genetic_algorithm.ipynb#ch0000005?line=5'>6</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, generation_count):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Riad/Desktop/MASTER%202/PROJET_CODE/genetic_algorithm.ipynb#ch0000005?line=6'>7</a>\u001b[0m   \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mgeneration \u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Riad/Desktop/MASTER%202/PROJET_CODE/genetic_algorithm.ipynb#ch0000005?line=7'>8</a>\u001b[0m   fitnesses \u001b[39m=\u001b[39m calc_fitnesses(population)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Riad/Desktop/MASTER%202/PROJET_CODE/genetic_algorithm.ipynb#ch0000005?line=8'>9</a>\u001b[0m   best \u001b[39m=\u001b[39m get_best(fitnesses)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Riad/Desktop/MASTER%202/PROJET_CODE/genetic_algorithm.ipynb#ch0000005?line=9'>10</a>\u001b[0m   \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBest: \u001b[39m\u001b[39m{\u001b[39;00mfitnesses[best]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32mc:\\Users\\Riad\\Desktop\\MASTER 2\\PROJET_CODE\\genetic_algorithm.ipynb Cell 3'\u001b[0m in \u001b[0;36mcalc_fitnesses\u001b[1;34m(population)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Riad/Desktop/MASTER%202/PROJET_CODE/genetic_algorithm.ipynb#ch0000001?line=26'>27</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(population_count):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Riad/Desktop/MASTER%202/PROJET_CODE/genetic_algorithm.ipynb#ch0000001?line=27'>28</a>\u001b[0m   model \u001b[39m=\u001b[39m AutoEncoder(population[i])\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Riad/Desktop/MASTER%202/PROJET_CODE/genetic_algorithm.ipynb#ch0000001?line=28'>29</a>\u001b[0m   model\u001b[39m.\u001b[39;49mfit(train_x, train_x, epoches\u001b[39m=\u001b[39;49m\u001b[39m1600\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m600\u001b[39;49m, progress\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Riad/Desktop/MASTER%202/PROJET_CODE/genetic_algorithm.ipynb#ch0000001?line=29'>30</a>\u001b[0m   fitnesses\u001b[39m.\u001b[39mappend(model\u001b[39m.\u001b[39mcurrent_loss)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Riad/Desktop/MASTER%202/PROJET_CODE/genetic_algorithm.ipynb#ch0000001?line=30'>31</a>\u001b[0m \u001b[39mreturn\u001b[39;00m fitnesses\n",
      "File \u001b[1;32mc:\\Users\\Riad\\Desktop\\MASTER 2\\PROJET_CODE\\AutoEncoder.py:73\u001b[0m, in \u001b[0;36mAutoEncoder.fit\u001b[1;34m(self, data_x, data_y, epoches, batch_size, progress)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/Riad/Desktop/MASTER%202/PROJET_CODE/AutoEncoder.py?line=70'>71</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mopti\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m     <a href='file:///c%3A/Users/Riad/Desktop/MASTER%202/PROJET_CODE/AutoEncoder.py?line=71'>72</a>\u001b[0m   loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m---> <a href='file:///c%3A/Users/Riad/Desktop/MASTER%202/PROJET_CODE/AutoEncoder.py?line=72'>73</a>\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mopti\u001b[39m.\u001b[39;49mstep()\n\u001b[0;32m     <a href='file:///c%3A/Users/Riad/Desktop/MASTER%202/PROJET_CODE/AutoEncoder.py?line=74'>75</a>\u001b[0m \u001b[39mif\u001b[39;00m progress:\n\u001b[0;32m     <a href='file:///c%3A/Users/Riad/Desktop/MASTER%202/PROJET_CODE/AutoEncoder.py?line=75'>76</a>\u001b[0m   \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mepoche: \u001b[39m\u001b[39m{\u001b[39;00mepoche\u001b[39m}\u001b[39;00m\u001b[39m, loss: \u001b[39m\u001b[39m{\u001b[39;00mloss\u001b[39m.\u001b[39mitem()\u001b[39m:\u001b[39;00m\u001b[39m.8f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Riad\\Desktop\\MASTER 2\\PROJET_CODE\\venv\\lib\\site-packages\\torch\\optim\\optimizer.py:88\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/Riad/Desktop/MASTER%202/PROJET_CODE/venv/lib/site-packages/torch/optim/optimizer.py?line=85'>86</a>\u001b[0m profile_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mOptimizer.step#\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.step\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(obj\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[0;32m     <a href='file:///c%3A/Users/Riad/Desktop/MASTER%202/PROJET_CODE/venv/lib/site-packages/torch/optim/optimizer.py?line=86'>87</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mrecord_function(profile_name):\n\u001b[1;32m---> <a href='file:///c%3A/Users/Riad/Desktop/MASTER%202/PROJET_CODE/venv/lib/site-packages/torch/optim/optimizer.py?line=87'>88</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Riad\\Desktop\\MASTER 2\\PROJET_CODE\\venv\\lib\\site-packages\\torch\\autograd\\grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/Riad/Desktop/MASTER%202/PROJET_CODE/venv/lib/site-packages/torch/autograd/grad_mode.py?line=23'>24</a>\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[0;32m     <a href='file:///c%3A/Users/Riad/Desktop/MASTER%202/PROJET_CODE/venv/lib/site-packages/torch/autograd/grad_mode.py?line=24'>25</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     <a href='file:///c%3A/Users/Riad/Desktop/MASTER%202/PROJET_CODE/venv/lib/site-packages/torch/autograd/grad_mode.py?line=25'>26</a>\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[1;32m---> <a href='file:///c%3A/Users/Riad/Desktop/MASTER%202/PROJET_CODE/venv/lib/site-packages/torch/autograd/grad_mode.py?line=26'>27</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Riad\\Desktop\\MASTER 2\\PROJET_CODE\\venv\\lib\\site-packages\\torch\\optim\\adam.py:141\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Riad/Desktop/MASTER%202/PROJET_CODE/venv/lib/site-packages/torch/optim/adam.py?line=137'>138</a>\u001b[0m             \u001b[39m# record the step after step update\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Riad/Desktop/MASTER%202/PROJET_CODE/venv/lib/site-packages/torch/optim/adam.py?line=138'>139</a>\u001b[0m             state_steps\u001b[39m.\u001b[39mappend(state[\u001b[39m'\u001b[39m\u001b[39mstep\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m--> <a href='file:///c%3A/Users/Riad/Desktop/MASTER%202/PROJET_CODE/venv/lib/site-packages/torch/optim/adam.py?line=140'>141</a>\u001b[0m     F\u001b[39m.\u001b[39;49madam(params_with_grad,\n\u001b[0;32m    <a href='file:///c%3A/Users/Riad/Desktop/MASTER%202/PROJET_CODE/venv/lib/site-packages/torch/optim/adam.py?line=141'>142</a>\u001b[0m            grads,\n\u001b[0;32m    <a href='file:///c%3A/Users/Riad/Desktop/MASTER%202/PROJET_CODE/venv/lib/site-packages/torch/optim/adam.py?line=142'>143</a>\u001b[0m            exp_avgs,\n\u001b[0;32m    <a href='file:///c%3A/Users/Riad/Desktop/MASTER%202/PROJET_CODE/venv/lib/site-packages/torch/optim/adam.py?line=143'>144</a>\u001b[0m            exp_avg_sqs,\n\u001b[0;32m    <a href='file:///c%3A/Users/Riad/Desktop/MASTER%202/PROJET_CODE/venv/lib/site-packages/torch/optim/adam.py?line=144'>145</a>\u001b[0m            max_exp_avg_sqs,\n\u001b[0;32m    <a href='file:///c%3A/Users/Riad/Desktop/MASTER%202/PROJET_CODE/venv/lib/site-packages/torch/optim/adam.py?line=145'>146</a>\u001b[0m            state_steps,\n\u001b[0;32m    <a href='file:///c%3A/Users/Riad/Desktop/MASTER%202/PROJET_CODE/venv/lib/site-packages/torch/optim/adam.py?line=146'>147</a>\u001b[0m            amsgrad\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mamsgrad\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    <a href='file:///c%3A/Users/Riad/Desktop/MASTER%202/PROJET_CODE/venv/lib/site-packages/torch/optim/adam.py?line=147'>148</a>\u001b[0m            beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[0;32m    <a href='file:///c%3A/Users/Riad/Desktop/MASTER%202/PROJET_CODE/venv/lib/site-packages/torch/optim/adam.py?line=148'>149</a>\u001b[0m            beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[0;32m    <a href='file:///c%3A/Users/Riad/Desktop/MASTER%202/PROJET_CODE/venv/lib/site-packages/torch/optim/adam.py?line=149'>150</a>\u001b[0m            lr\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mlr\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    <a href='file:///c%3A/Users/Riad/Desktop/MASTER%202/PROJET_CODE/venv/lib/site-packages/torch/optim/adam.py?line=150'>151</a>\u001b[0m            weight_decay\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mweight_decay\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    <a href='file:///c%3A/Users/Riad/Desktop/MASTER%202/PROJET_CODE/venv/lib/site-packages/torch/optim/adam.py?line=151'>152</a>\u001b[0m            eps\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39meps\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    <a href='file:///c%3A/Users/Riad/Desktop/MASTER%202/PROJET_CODE/venv/lib/site-packages/torch/optim/adam.py?line=152'>153</a>\u001b[0m            maximize\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mmaximize\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[0;32m    <a href='file:///c%3A/Users/Riad/Desktop/MASTER%202/PROJET_CODE/venv/lib/site-packages/torch/optim/adam.py?line=153'>154</a>\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32mc:\\Users\\Riad\\Desktop\\MASTER 2\\PROJET_CODE\\venv\\lib\\site-packages\\torch\\optim\\_functional.py:105\u001b[0m, in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Riad/Desktop/MASTER%202/PROJET_CODE/venv/lib/site-packages/torch/optim/_functional.py?line=102'>103</a>\u001b[0m     denom \u001b[39m=\u001b[39m (max_exp_avg_sqs[i]\u001b[39m.\u001b[39msqrt() \u001b[39m/\u001b[39m math\u001b[39m.\u001b[39msqrt(bias_correction2))\u001b[39m.\u001b[39madd_(eps)\n\u001b[0;32m    <a href='file:///c%3A/Users/Riad/Desktop/MASTER%202/PROJET_CODE/venv/lib/site-packages/torch/optim/_functional.py?line=103'>104</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/Riad/Desktop/MASTER%202/PROJET_CODE/venv/lib/site-packages/torch/optim/_functional.py?line=104'>105</a>\u001b[0m     denom \u001b[39m=\u001b[39m (exp_avg_sq\u001b[39m.\u001b[39;49msqrt() \u001b[39m/\u001b[39;49m math\u001b[39m.\u001b[39;49msqrt(bias_correction2))\u001b[39m.\u001b[39madd_(eps)\n\u001b[0;32m    <a href='file:///c%3A/Users/Riad/Desktop/MASTER%202/PROJET_CODE/venv/lib/site-packages/torch/optim/_functional.py?line=108'>109</a>\u001b[0m step_size \u001b[39m=\u001b[39m lr \u001b[39m/\u001b[39m bias_correction1\n\u001b[0;32m    <a href='file:///c%3A/Users/Riad/Desktop/MASTER%202/PROJET_CODE/venv/lib/site-packages/torch/optim/_functional.py?line=109'>110</a>\u001b[0m param\u001b[39m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[39m=\u001b[39m\u001b[39m-\u001b[39mstep_size)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# # # # #\n",
    "population = generate_population()\n",
    "global_best = None\n",
    "global_best_fitness = None\n",
    "\n",
    "for i in range(0, generation_count):\n",
    "  print(f\"generation {i+1}\")\n",
    "  fitnesses = calc_fitnesses(population)\n",
    "  best = get_best(fitnesses)\n",
    "  print(f\"Best: {fitnesses[best]}\")\n",
    "  if global_best == None:\n",
    "      global_best = population[best]\n",
    "      global_best_fitness = fitnesses[best]\n",
    "  elif global_best_fitness > fitnesses[best]:\n",
    "      global_best = population[best]\n",
    "      global_best_fitness = fitnesses[best]\n",
    "\n",
    "  best_two = get_bests(fitnesses, 2)\n",
    "  \n",
    "  population = [\n",
    "    population[best_two[0]],\n",
    "    population[best_two[1]],\n",
    "    breed(population[best_two[0]], population[best_two[1]]),\n",
    "    breed(population[best_two[1]], population[best_two[0]]),\n",
    "  ]\n",
    "\n",
    "print(f\"global best: {global_best_fitness}\")\n",
    "print(global_best)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7, 12, 12]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_best\n",
    "# global_best_fitness\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "72c063d6035d88959ce5488d2496817d169a349dc57db45346e17e4ac662e96d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
