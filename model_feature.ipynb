{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utils import toTorchTensers, NormalizeData\n",
    "from Models import ForcastModel\n",
    "\n",
    "data_url = r'./data/New_Feats_12-04_12-09-09.xlsx'\n",
    "data_egypt = pd.read_excel(data_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.78375769 0.82975703 0.65604067]\n",
      " [0.         0.46389538 0.12236483 0.42620859]\n",
      " [0.         0.24049922 0.71626908 0.4170197 ]\n",
      " ...\n",
      " [1.         0.48928325 0.36004919 0.45143803]\n",
      " [1.         0.3293826  0.42042672 0.70597426]\n",
      " [1.         0.74629243 0.43832318 0.60340073]]\n"
     ]
    }
   ],
   "source": [
    "# data\n",
    "DATA = data_egypt\n",
    "DATA = NormalizeData(DATA)\n",
    "DATA = DATA.to_numpy()\n",
    "DATA = DATA[:, 1:]\n",
    "print(DATA)\n",
    "\n",
    "np.random.seed(1)\n",
    "np.random.shuffle(DATA)\n",
    "split_point = math.floor(len(DATA) * 0.75)\n",
    "\n",
    "train_x, train_y = DATA[:split_point, 1:], DATA[:split_point, 0:1]\n",
    "test_x, test_y = DATA[split_point:, 1:], DATA[split_point:, 0:1]\n",
    "\n",
    "[train_x, train_y, test_x, test_y] = toTorchTensers(\n",
    "  train_x, train_y, test_x, test_y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoche: 0, loss: 0.22738655, execution time: 1.4s\n",
      "epoche: 1, loss: 0.22199683, execution time: 1.3s\n",
      "epoche: 2, loss: 0.22363076, execution time: 1.5s\n",
      "epoche: 3, loss: 0.22397846, execution time: 1.4s\n",
      "epoche: 4, loss: 0.22419631, execution time: 1.4s\n",
      "epoche: 5, loss: 0.22446391, execution time: 1.4s\n",
      "epoche: 6, loss: 0.22467363, execution time: 1.5s\n",
      "epoche: 7, loss: 0.22486265, execution time: 1.7s\n",
      "epoche: 8, loss: 0.22501217, execution time: 1.6s\n",
      "epoche: 9, loss: 0.22514610, execution time: 1.4s\n",
      "epoche: 10, loss: 0.22527115, execution time: 1.4s\n",
      "epoche: 11, loss: 0.22536646, execution time: 1.5s\n",
      "epoche: 12, loss: 0.22457764, execution time: 1.5s\n",
      "epoche: 13, loss: 0.22535191, execution time: 1.5s\n",
      "epoche: 14, loss: 0.22559117, execution time: 1.5s\n",
      "epoche: 15, loss: 0.22570278, execution time: 1.5s\n",
      "epoche: 16, loss: 0.22575822, execution time: 1.5s\n",
      "epoche: 17, loss: 0.22577995, execution time: 1.6s\n",
      "epoche: 18, loss: 0.22578779, execution time: 1.5s\n",
      "epoche: 19, loss: 0.22580099, execution time: 1.7s\n",
      "epoche: 20, loss: 0.22582832, execution time: 2.5s\n",
      "epoche: 21, loss: 0.22584611, execution time: 1.7s\n",
      "epoche: 22, loss: 0.22586906, execution time: 1.9s\n",
      "epoche: 23, loss: 0.22589353, execution time: 1.7s\n",
      "epoche: 24, loss: 0.22591798, execution time: 1.7s\n",
      "epoche: 25, loss: 0.22594297, execution time: 1.7s\n",
      "epoche: 26, loss: 0.22596900, execution time: 2.4s\n",
      "epoche: 27, loss: 0.22599596, execution time: 1.9s\n",
      "epoche: 28, loss: 0.22602309, execution time: 1.8s\n",
      "epoche: 29, loss: 0.22605240, execution time: 1.7s\n",
      "epoche: 30, loss: 0.22608213, execution time: 2.0s\n",
      "epoche: 31, loss: 0.22611274, execution time: 2.2s\n",
      "epoche: 32, loss: 0.22614272, execution time: 1.9s\n",
      "epoche: 33, loss: 0.22617175, execution time: 1.8s\n",
      "epoche: 34, loss: 0.22619772, execution time: 2.0s\n",
      "epoche: 35, loss: 0.22621654, execution time: 2.3s\n",
      "epoche: 36, loss: 0.22622204, execution time: 2.1s\n",
      "epoche: 37, loss: 0.22620951, execution time: 1.9s\n",
      "epoche: 38, loss: 0.22618623, execution time: 1.8s\n",
      "epoche: 39, loss: 0.22616248, execution time: 1.8s\n",
      "epoche: 40, loss: 0.22573458, execution time: 2.1s\n",
      "epoche: 41, loss: 0.22600947, execution time: 1.9s\n",
      "epoche: 42, loss: 0.22602032, execution time: 1.8s\n",
      "epoche: 43, loss: 0.22599483, execution time: 1.8s\n",
      "epoche: 44, loss: 0.22580974, execution time: 1.9s\n",
      "epoche: 45, loss: 0.22597535, execution time: 1.9s\n",
      "epoche: 46, loss: 0.22597155, execution time: 1.8s\n",
      "epoche: 47, loss: 0.22595680, execution time: 1.8s\n",
      "epoche: 48, loss: 0.22594614, execution time: 1.7s\n",
      "epoche: 49, loss: 0.22593851, execution time: 1.7s\n",
      "âœ… training ended ,final loss: 0.22593851, time: 87.1s\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "model = ForcastModel(input=3)\n",
    "model.fit(train_x, train_y, epoches=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.2259, acc: 0.4550\n"
     ]
    }
   ],
   "source": [
    "# testing\n",
    "model.test(test_x, test_y, bar=0.7)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "72c063d6035d88959ce5488d2496817d169a349dc57db45346e17e4ac662e96d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
